{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Gesture Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules and define wavelet function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "def wavelet(data, level, wavelet):\n",
    "    (cA, cD) = pywt.dwt(data, wavelet=wavelet)\n",
    "    for i in range(1, level):\n",
    "        (cA, cD) = pywt.dwt(cA, wavelet=wavelet)\n",
    "    return cA, cD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and perform wavelet transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9,\n",
    "    10\n",
    "]\n",
    "num_samples = 50\n",
    "num_gestures = len(gestures)\n",
    "\n",
    "fulldata = pd.DataFrame(columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "fullwavedata = pd.DataFrame(columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'])\n",
    "formatdata = pd.DataFrame()\n",
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "labels = []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        filepath = 'hand/hand_{0}_{1}.csv'.format(gesture, i)\n",
    "        data = pd.read_csv(filepath, index_col=False)\n",
    "        wavedata = pd.DataFrame()\n",
    "        \n",
    "        level1 = 3\n",
    "        wavetype1 = 'rbio2.2'\n",
    "        #Start creating the dataframe with transformed data\n",
    "        wavedata['aX_A1'], wavedata['aX_D1'] = wavelet(data['aX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aY_A1'], wavedata['aY_D1'] = wavelet(data['aY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['aZ_A1'], wavedata['aZ_D1'] = wavelet(data['aZ'], level=level1, wavelet=wavetype1)\n",
    "\n",
    "        wavedata['gX_A1'], wavedata['gX_D1'] = wavelet(data['gX'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gY_A1'], wavedata['gY_D1'] = wavelet(data['gY'], level=level1, wavelet=wavetype1)\n",
    "        wavedata['gZ_A1'], wavedata['gZ_D1'] = wavelet(data['gZ'], level=level1, wavelet=wavetype1)\n",
    "        \n",
    "        level2 = 3\n",
    "        wavetype2 = 'rbio2.2'\n",
    "\n",
    "        wavedata['aX_A2'], wavedata['aX_D2'] = wavelet(data['aX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aY_A2'], wavedata['aY_D2'] = wavelet(data['aY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['aZ_A2'], wavedata['aZ_D2'] = wavelet(data['aZ'], level=level2, wavelet=wavetype2)\n",
    "\n",
    "        wavedata['gX_A2'], wavedata['gX_D2'] = wavelet(data['gX'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gY_A2'], wavedata['gY_D2'] = wavelet(data['gY'], level=level2, wavelet=wavetype2)\n",
    "        wavedata['gZ_A2'], wavedata['gZ_D2'] = wavelet(data['gZ'], level=level2, wavelet=wavetype2)\n",
    "        \n",
    "        wavelen = len(wavedata)\n",
    "        \n",
    "        #create a full dataframe with all the data\n",
    "        fullwavedata = fullwavedata.append(wavedata)\n",
    "        fulldata = fulldata.append(data)\n",
    "        label = gesture\n",
    "        labels.append(label)\n",
    "        del data, wavedata\n",
    "\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX</th>\n",
       "      <th>aY</th>\n",
       "      <th>aZ</th>\n",
       "      <th>gX</th>\n",
       "      <th>gY</th>\n",
       "      <th>gZ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "      <td>192500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.400953</td>\n",
       "      <td>0.508082</td>\n",
       "      <td>0.541712</td>\n",
       "      <td>0.499318</td>\n",
       "      <td>0.427822</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.074306</td>\n",
       "      <td>0.068467</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.096042</td>\n",
       "      <td>0.095247</td>\n",
       "      <td>0.095711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.377844</td>\n",
       "      <td>0.486061</td>\n",
       "      <td>0.488569</td>\n",
       "      <td>0.484298</td>\n",
       "      <td>0.406824</td>\n",
       "      <td>0.492653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.388312</td>\n",
       "      <td>0.508553</td>\n",
       "      <td>0.539899</td>\n",
       "      <td>0.505739</td>\n",
       "      <td>0.420533</td>\n",
       "      <td>0.502602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.411963</td>\n",
       "      <td>0.535409</td>\n",
       "      <td>0.591876</td>\n",
       "      <td>0.521076</td>\n",
       "      <td>0.432317</td>\n",
       "      <td>0.517067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  aX             aY             aZ             gX  \\\n",
       "count  192500.000000  192500.000000  192500.000000  192500.000000   \n",
       "mean        0.400953       0.508082       0.541712       0.499318   \n",
       "std         0.074306       0.068467       0.085276       0.096042   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.377844       0.486061       0.488569       0.484298   \n",
       "50%         0.388312       0.508553       0.539899       0.505739   \n",
       "75%         0.411963       0.535409       0.591876       0.521076   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "                  gY             gZ  \n",
       "count  192500.000000  192500.000000  \n",
       "mean        0.427822       0.502331  \n",
       "std         0.095247       0.095711  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.406824       0.492653  \n",
       "50%         0.420533       0.502602  \n",
       "75%         0.432317       0.517067  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldata = fulldata.iloc[0:,0:6]\n",
    "normaldata = (fulldata - fulldata.min()) / (fulldata.max()-fulldata.min())\n",
    "normaldata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save maximum and minimum values for use in the prediction model on the PocketBeagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fulldata.min(), dtype='float32')\n",
    "maxval = np.array(fulldata.max(), dtype='float32')\n",
    "\n",
    "parameters_full = pd.DataFrame([minval, maxval], columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "parameters_full.to_csv('parameters_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data into numpy array for use with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36514839, 0.40900282, 0.53687994, ..., 0.49930897, 0.43952637,\n",
       "        0.49567407],\n",
       "       [0.36826123, 0.55677119, 0.61452193, ..., 0.50932893, 0.42393172,\n",
       "        0.49123369],\n",
       "       [0.37146563, 0.4280766 , 0.58713156, ..., 0.50639205, 0.42553788,\n",
       "        0.49358358],\n",
       "       ...,\n",
       "       [0.3648127 , 0.37119097, 0.40265996, ..., 0.50357033, 0.42159719,\n",
       "        0.49990082],\n",
       "       [0.38944076, 0.36267643, 0.41401869, ..., 0.50669917, 0.41905722,\n",
       "        0.51453422],\n",
       "       [0.37061112, 0.37793545, 0.42573688, ..., 0.50518274, 0.41803003,\n",
       "        0.50209812]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatdata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*350 + (i-1) * 350\n",
    "        #print(index, index+250)\n",
    "        dataf = normaldata.iloc[index:index+350].to_numpy().flatten().tolist()\n",
    "        formatdata[idx*num_samples+i-1] = dataf\n",
    "        del dataf\n",
    "        \n",
    "        \n",
    "formatdata = formatdata.transpose().to_numpy()\n",
    "formatdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelet Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save parameters from wavelet transformed data for use in PocketBeagle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "minval = np.array(fullwavedata.min(), dtype='float32')\n",
    "maxval = np.array(fullwavedata.max(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = pd.DataFrame([minval, maxval], columns = ['aX_A1','aX_D1','aY_A1','aY_D1','aZ_A1','aZ_D1','gX_A1','gX_D1','gY_A1','gY_D1','gZ_A1','gZ_D1',\n",
    "                                       'aX_A2','aX_D2','aY_A2','aY_D2','aZ_A2','aZ_D2','gX_A2','gX_D2','gY_A2','gY_D2','gZ_A2','gZ_D2'], index=['min','max'])\n",
    "parameters.to_csv('dataparameters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Wavelet Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aX_A1</th>\n",
       "      <th>aX_D1</th>\n",
       "      <th>aY_A1</th>\n",
       "      <th>aY_D1</th>\n",
       "      <th>aZ_A1</th>\n",
       "      <th>aZ_D1</th>\n",
       "      <th>gX_A1</th>\n",
       "      <th>gX_D1</th>\n",
       "      <th>gY_A1</th>\n",
       "      <th>gY_D1</th>\n",
       "      <th>...</th>\n",
       "      <th>aY_A2</th>\n",
       "      <th>aY_D2</th>\n",
       "      <th>aZ_A2</th>\n",
       "      <th>aZ_D2</th>\n",
       "      <th>gX_A2</th>\n",
       "      <th>gX_D2</th>\n",
       "      <th>gY_A2</th>\n",
       "      <th>gY_D2</th>\n",
       "      <th>gZ_A2</th>\n",
       "      <th>gZ_D2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "      <td>26400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.335526</td>\n",
       "      <td>0.611492</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432839</td>\n",
       "      <td>0.449727</td>\n",
       "      <td>0.558324</td>\n",
       "      <td>0.521365</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>0.519830</td>\n",
       "      <td>0.410186</td>\n",
       "      <td>0.521206</td>\n",
       "      <td>0.502551</td>\n",
       "      <td>0.583230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.080657</td>\n",
       "      <td>0.031527</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083774</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>0.097088</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>0.102759</td>\n",
       "      <td>0.048254</td>\n",
       "      <td>0.099510</td>\n",
       "      <td>0.040963</td>\n",
       "      <td>0.090144</td>\n",
       "      <td>0.035227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.311361</td>\n",
       "      <td>0.608447</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403568</td>\n",
       "      <td>0.446310</td>\n",
       "      <td>0.494259</td>\n",
       "      <td>0.515400</td>\n",
       "      <td>0.482615</td>\n",
       "      <td>0.515702</td>\n",
       "      <td>0.388433</td>\n",
       "      <td>0.517965</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.579189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.322813</td>\n",
       "      <td>0.611240</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435093</td>\n",
       "      <td>0.449777</td>\n",
       "      <td>0.557355</td>\n",
       "      <td>0.521536</td>\n",
       "      <td>0.506969</td>\n",
       "      <td>0.519877</td>\n",
       "      <td>0.404442</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.502341</td>\n",
       "      <td>0.582993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.347766</td>\n",
       "      <td>0.613706</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470832</td>\n",
       "      <td>0.453207</td>\n",
       "      <td>0.617096</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.523956</td>\n",
       "      <td>0.524138</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.525350</td>\n",
       "      <td>0.515112</td>\n",
       "      <td>0.586998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              aX_A1         aX_D1         aY_A1         aY_D1         aZ_A1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.335526      0.611492      0.432839      0.449727      0.558324   \n",
       "std        0.080657      0.031527      0.083774      0.033548      0.097088   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.311361      0.608447      0.403568      0.446310      0.494259   \n",
       "50%        0.322813      0.611240      0.435093      0.449777      0.557355   \n",
       "75%        0.347766      0.613706      0.470832      0.453207      0.617096   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              aZ_D1         gX_A1         gX_D1         gY_A1         gY_D1  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.521365      0.500183      0.519830      0.410186      0.521206   \n",
       "std        0.042426      0.102759      0.048254      0.099510      0.040963   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.515400      0.482615      0.515702      0.388433      0.517965   \n",
       "50%        0.521536      0.506969      0.519877      0.404442      0.521259   \n",
       "75%        0.527778      0.523956      0.524138      0.415941      0.525350   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...         aY_A2         aY_D2         aZ_A2         aZ_D2  \\\n",
       "count  ...  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean   ...      0.432839      0.449727      0.558324      0.521365   \n",
       "std    ...      0.083774      0.033548      0.097088      0.042426   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.403568      0.446310      0.494259      0.515400   \n",
       "50%    ...      0.435093      0.449777      0.557355      0.521536   \n",
       "75%    ...      0.470832      0.453207      0.617096      0.527778   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gX_A2         gX_D2         gY_A2         gY_D2         gZ_A2  \\\n",
       "count  26400.000000  26400.000000  26400.000000  26400.000000  26400.000000   \n",
       "mean       0.500183      0.519830      0.410186      0.521206      0.502551   \n",
       "std        0.102759      0.048254      0.099510      0.040963      0.090144   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.482615      0.515702      0.388433      0.517965      0.492884   \n",
       "50%        0.506969      0.519877      0.404442      0.521259      0.502341   \n",
       "75%        0.523956      0.524138      0.415941      0.525350      0.515112   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              gZ_D2  \n",
       "count  26400.000000  \n",
       "mean       0.583230  \n",
       "std        0.035227  \n",
       "min        0.000000  \n",
       "25%        0.579189  \n",
       "50%        0.582993  \n",
       "75%        0.586998  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalwavedata = (fullwavedata - fullwavedata.min()) / (fullwavedata.max()-fullwavedata.min())\n",
    "normalwavedata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data into numpy array for use with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29540231, 0.61156848, 0.27991591, ..., 0.5188936 , 0.4929458 ,\n",
       "        0.58779549],\n",
       "       [0.29813013, 0.61073137, 0.50787481, ..., 0.52143732, 0.49012884,\n",
       "        0.58391459],\n",
       "       [0.30318832, 0.61109519, 0.3142718 , ..., 0.52195295, 0.49385348,\n",
       "        0.58364604],\n",
       "       ...,\n",
       "       [0.31135546, 0.61839787, 0.23596859, ..., 0.51909722, 0.50125362,\n",
       "        0.58275752],\n",
       "       [0.39471096, 0.63080849, 0.24139908, ..., 0.52259185, 0.51834611,\n",
       "        0.58284503],\n",
       "       [0.30184074, 0.61630349, 0.20849859, ..., 0.52138206, 0.5016146 ,\n",
       "        0.58184442]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatwavedata = pd.DataFrame()\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        \n",
    "        index = idx*num_samples*wavelen + (i-1) * wavelen\n",
    "        #print(index, index+250)\n",
    "        wavedataf = normalwavedata.iloc[index:index+wavelen].to_numpy().flatten().tolist()\n",
    "        formatwavedata[idx*num_samples+i-1] = wavedataf\n",
    "        del wavedataf\n",
    "        \n",
    "        \n",
    "formatwavedata = formatwavedata.transpose().to_numpy()\n",
    "formatwavedata \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training, test, and validation.\n",
    "Using StratifiedShuffleSplit to ensure even distribution of all the gestures in every dataset. (This is especially useful for small datasets such as this one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "1: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "2: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "3: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "4: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "5: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "6: Train 0.09114583333333333; Test 0.0963855421686747; Val 0.08433734939759036\n",
      "7: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n",
      "8: Train 0.08854166666666667; Test 0.0963855421686747; Val 0.0963855421686747\n",
      "9: Train 0.09114583333333333; Test 0.08433734939759036; Val 0.0963855421686747\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15)\n",
    "valsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.15/0.85)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "for train_index, val_index in valsplit.split(X_train, y_train):\n",
    "    X_train, X_val = X_train[train_index], X_train[val_index]\n",
    "    y_train, y_val = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "for i in range(0,10):\n",
    "    print('{3}: Train {0}; Test {1}; Val {2}'.format(np.size(np.where(y_train == i)) / len(y_train), np.size(np.where(y_test == i)) / len(y_test), np.size(np.where(y_val == i)) / len(y_val), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up TensorFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25)) #dropout layers help prevent overfitting\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model using optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "12/12 [==============================] - 2s 85ms/step - loss: 2.4466 - sparse_categorical_accuracy: 0.0833 - val_loss: 2.3521 - val_sparse_categorical_accuracy: 0.1446\n",
      "Epoch 2/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 2.4043 - sparse_categorical_accuracy: 0.1120 - val_loss: 2.3151 - val_sparse_categorical_accuracy: 0.3133\n",
      "Epoch 3/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.3438 - sparse_categorical_accuracy: 0.1510 - val_loss: 2.2696 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 4/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 2.3190 - sparse_categorical_accuracy: 0.1927 - val_loss: 2.2330 - val_sparse_categorical_accuracy: 0.3253\n",
      "Epoch 5/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 2.2646 - sparse_categorical_accuracy: 0.2474 - val_loss: 2.1805 - val_sparse_categorical_accuracy: 0.5181\n",
      "Epoch 6/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 2.2371 - sparse_categorical_accuracy: 0.2370 - val_loss: 2.1384 - val_sparse_categorical_accuracy: 0.4337\n",
      "Epoch 7/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 2.1829 - sparse_categorical_accuracy: 0.3073 - val_loss: 2.0595 - val_sparse_categorical_accuracy: 0.6988\n",
      "Epoch 8/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 2.0966 - sparse_categorical_accuracy: 0.3229 - val_loss: 1.9841 - val_sparse_categorical_accuracy: 0.5904\n",
      "Epoch 9/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 2.0496 - sparse_categorical_accuracy: 0.3438 - val_loss: 1.9190 - val_sparse_categorical_accuracy: 0.4699\n",
      "Epoch 10/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.9573 - sparse_categorical_accuracy: 0.3984 - val_loss: 1.7941 - val_sparse_categorical_accuracy: 0.5783\n",
      "Epoch 11/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 1.8747 - sparse_categorical_accuracy: 0.4505 - val_loss: 1.7089 - val_sparse_categorical_accuracy: 0.6627\n",
      "Epoch 12/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.7895 - sparse_categorical_accuracy: 0.4531 - val_loss: 1.6440 - val_sparse_categorical_accuracy: 0.5663\n",
      "Epoch 13/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.7055 - sparse_categorical_accuracy: 0.4792 - val_loss: 1.5554 - val_sparse_categorical_accuracy: 0.5783\n",
      "Epoch 14/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.5578 - sparse_categorical_accuracy: 0.5755 - val_loss: 1.3947 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 15/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.4686 - sparse_categorical_accuracy: 0.5911 - val_loss: 1.4269 - val_sparse_categorical_accuracy: 0.5542\n",
      "Epoch 16/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 1.3498 - sparse_categorical_accuracy: 0.6432 - val_loss: 1.2326 - val_sparse_categorical_accuracy: 0.7831\n",
      "Epoch 17/600\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 1.2726 - sparse_categorical_accuracy: 0.6589 - val_loss: 1.1231 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 18/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.1751 - sparse_categorical_accuracy: 0.6771 - val_loss: 1.0517 - val_sparse_categorical_accuracy: 0.8193\n",
      "Epoch 19/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.1167 - sparse_categorical_accuracy: 0.7240 - val_loss: 1.0549 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 20/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.0749 - sparse_categorical_accuracy: 0.7057 - val_loss: 0.9845 - val_sparse_categorical_accuracy: 0.7831\n",
      "Epoch 21/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.0208 - sparse_categorical_accuracy: 0.7057 - val_loss: 0.9828 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 22/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.9547 - sparse_categorical_accuracy: 0.7656 - val_loss: 0.8512 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 23/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.8340 - sparse_categorical_accuracy: 0.8099 - val_loss: 0.7582 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 24/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.8048 - sparse_categorical_accuracy: 0.8151 - val_loss: 0.7268 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 25/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.7514 - sparse_categorical_accuracy: 0.8047 - val_loss: 0.8228 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 26/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.7015 - sparse_categorical_accuracy: 0.8177 - val_loss: 0.6659 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 27/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.6341 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.6619 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 28/600\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.6043 - sparse_categorical_accuracy: 0.8516 - val_loss: 0.6090 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 29/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.5739 - sparse_categorical_accuracy: 0.8542 - val_loss: 0.5410 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 30/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.5604 - sparse_categorical_accuracy: 0.8698 - val_loss: 0.5586 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 31/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.5189 - sparse_categorical_accuracy: 0.8594 - val_loss: 0.5993 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 32/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.4783 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.5173 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 33/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.8724 - val_loss: 0.5242 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 34/600\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.4752 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.4434 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 35/600\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.4791 - sparse_categorical_accuracy: 0.8906 - val_loss: 0.6070 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 36/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.4759 - sparse_categorical_accuracy: 0.8620 - val_loss: 0.4896 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 37/600\n",
      "12/12 [==============================] - 1s 87ms/step - loss: 0.4198 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.4054 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 38/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.3696 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.4211 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 39/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.3678 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.3970 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 40/600\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.3377 - sparse_categorical_accuracy: 0.9089 - val_loss: 0.3481 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 41/600\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.3348 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.4081 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 42/600\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.3144 - sparse_categorical_accuracy: 0.9193 - val_loss: 0.3958 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 43/600\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.2972 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3182 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 44/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3981 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 45/600\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.3128 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.3333 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 46/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 56ms/step - loss: 0.2877 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.3675 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 47/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.2529 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.3472 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 48/600\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.2477 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.3433 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 49/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.2640 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3478 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 50/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.2315 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.3614 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 51/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.2843 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 52/600\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.2079 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.2854 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 53/600\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.1994 - sparse_categorical_accuracy: 0.9609 - val_loss: 0.3082 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 54/600\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.2115 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2691 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 55/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.2040 - sparse_categorical_accuracy: 0.9453 - val_loss: 0.3103 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 56/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.2400 - sparse_categorical_accuracy: 0.9271 - val_loss: 0.3263 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 57/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.1920 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.2874 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 58/600\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.1953 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.2519 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 59/600\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.1774 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2522 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 60/600\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1753 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.3085 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 61/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9401 - val_loss: 0.2861 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 62/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.1606 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.2049 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 63/600\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.1553 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.3177 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 64/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1846 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2439 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 65/600\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1928 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.2148 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 66/600\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1702 - sparse_categorical_accuracy: 0.9479 - val_loss: 0.2576 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 67/600\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.1456 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2451 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 68/600\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.1772 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2561 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 69/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1590 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.3259 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 70/600\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2792 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 71/600\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1565 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.3419 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 72/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1542 - sparse_categorical_accuracy: 0.9557 - val_loss: 0.3594 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 73/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1419 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2636 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 74/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.1664 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2398 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 75/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1607 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.3721 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 76/600\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1741 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2994 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 77/600\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.1975 - sparse_categorical_accuracy: 0.9297 - val_loss: 0.2058 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 78/600\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1370 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 79/600\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.1427 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2644 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 80/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.1027 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.2271 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 81/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0853 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.2204 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 82/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.1271 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2783 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 83/600\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.1242 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.3430 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 84/600\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9740 - val_loss: 0.2886 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 85/600\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.1249 - sparse_categorical_accuracy: 0.9583 - val_loss: 0.3341 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 86/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.1182 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2914 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 87/600\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.0979 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.2968 - val_sparse_categorical_accuracy: 0.9398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6bf790df0>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "\n",
    ")\n",
    "model.fit(X_train, y_train, \n",
    "            epochs=600,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping],\n",
    "            validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2337 - sparse_categorical_accuracy: 0.9277\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1b6c183c370>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model for TensorFlowLite on PocketBeagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "data (Dense)                 (None, 1024)              1180672   \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "result (Dense)               (None, 11)                11275     \n",
      "=================================================================\n",
      "Total params: 3,291,147\n",
      "Trainable params: 3,291,147\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert TF model to TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmpe0py4zwf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmpe0py4zwf\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('test_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify TensorFlowLite model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'data_input', 'index': 0, 'shape': array([   1, 1152]), 'shape_signature': array([  -1, 1152]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='test_model.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(input_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1152"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_size = X_test[0].size\n",
    "testing_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.27108055, 0.60922673, 0.45772752, ..., 0.52093402, 0.48902781,\n",
       "       0.58226719])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.033 0.94  0.009 0.    0.    0.    0.018 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.998 0.    0.    0.    0.001 0.    0.   ]\n",
      " [0.    0.011 0.987 0.001 0.    0.    0.    0.001 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.977 0.012 0.    0.002 0.009 0.   ]\n",
      " [0.    0.999 0.001 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.001 0.    0.    0.    0.004 0.    0.958 0.    0.016 0.021 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.999 0.    0.    0.001 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.005 0.995 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.999 0.   ]\n",
      " [0.    0.    0.    0.    0.001 0.885 0.05  0.    0.004 0.059 0.   ]\n",
      " [0.    0.173 0.004 0.01  0.001 0.001 0.    0.716 0.012 0.083 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
      " [0.002 0.    0.    0.009 0.956 0.    0.008 0.    0.024 0.    0.   ]\n",
      " [1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.999 0.    0.    0.    0.    0.    0.   ]\n",
      " [0.001 0.    0.992 0.007 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.998 0.001 0.    0.    0.    0.    0.001 0.    0.    0.   ]\n",
      " [0.002 0.001 0.993 0.004 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.999 0.    0.    0.    0.    0.    0.    0.    0.001 0.   ]\n",
      " [0.927 0.    0.072 0.001 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.001 0.022 0.976 0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.001 0.    0.    0.    0.99  0.001 0.002 0.001 0.005 0.001]\n",
      " [0.    0.022 0.96  0.001 0.    0.    0.    0.017 0.    0.    0.   ]\n",
      " [0.991 0.    0.    0.    0.    0.    0.009 0.    0.    0.    0.   ]\n",
      " [0.    0.002 0.    0.    0.    0.    0.    0.993 0.    0.005 0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      " [0.013 0.    0.    0.    0.    0.    0.986 0.    0.    0.    0.   ]\n",
      " [0.    0.98  0.003 0.001 0.008 0.    0.001 0.001 0.001 0.005 0.   ]\n",
      " [0.    0.989 0.002 0.001 0.002 0.    0.    0.002 0.    0.004 0.   ]\n",
      " [0.    0.001 0.    0.    0.    0.033 0.642 0.    0.002 0.322 0.   ]]\n",
      "[ 2  4  2  5  1  6  6  8  3  0  9  5  7  9  4  0  4  2  1  2  1  0  3  5\n",
      "  2  0  7 10  6  1  1  5  3 10  6  8  7  7  2  8  9  5  3 10  7  6  9  3\n",
      "  9 10  4  9  8  0  4  6  2 10  0  7  0  6  8  7  1  1 10  2 10  6  4  9\n",
      "  3  5  4  8  3  8  0  4  3  5  5]\n"
     ]
    }
   ],
   "source": [
    "#Sometimes behaves weird if no resizing of array \n",
    "input_data = np.float32(X_test[0:32])\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(np.round(output_data, decimals=3))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 1 but expected 32 for dimension 0 of input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-ed01d186557a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m113\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36mset_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    605\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minterpreter\u001b[0m \u001b[0mcould\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mset\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \"\"\"\n\u001b[1;32m--> 607\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSetTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mresize_tensor_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 1 but expected 32 for dimension 0 of input 0."
     ]
    }
   ],
   "source": [
    "for i in range(0, 113):\n",
    "    input_data = np.float32(np.resize(X_test[i], (1, testing_size)))\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lbl = np.argmax(output, axis=1)\n",
    "test_lbl = y_test\n",
    "\n",
    "cm = confusion_matrix(test_lbl, output_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 2.4458 - sparse_categorical_accuracy: 0.0795 - val_loss: 2.3590 - val_sparse_categorical_accuracy: 0.1566\n",
      "Epoch 2/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 2.4176 - sparse_categorical_accuracy: 0.1136 - val_loss: 2.3129 - val_sparse_categorical_accuracy: 0.2530\n",
      "Epoch 3/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 2.3705 - sparse_categorical_accuracy: 0.1250 - val_loss: 2.2712 - val_sparse_categorical_accuracy: 0.2169\n",
      "Epoch 4/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 2.3019 - sparse_categorical_accuracy: 0.1955 - val_loss: 2.2228 - val_sparse_categorical_accuracy: 0.5301\n",
      "Epoch 5/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 2.2629 - sparse_categorical_accuracy: 0.2068 - val_loss: 2.1623 - val_sparse_categorical_accuracy: 0.4217\n",
      "Epoch 6/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 2.2068 - sparse_categorical_accuracy: 0.2455 - val_loss: 2.0974 - val_sparse_categorical_accuracy: 0.4940\n",
      "Epoch 7/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 2.1516 - sparse_categorical_accuracy: 0.3023 - val_loss: 2.0387 - val_sparse_categorical_accuracy: 0.5301\n",
      "Epoch 8/600\n",
      "14/14 [==============================] - 1s 64ms/step - loss: 2.0687 - sparse_categorical_accuracy: 0.3886 - val_loss: 1.9132 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 9/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 2.0039 - sparse_categorical_accuracy: 0.3955 - val_loss: 1.8043 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 10/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 1.8828 - sparse_categorical_accuracy: 0.4091 - val_loss: 1.7587 - val_sparse_categorical_accuracy: 0.7349\n",
      "Epoch 11/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 1.8070 - sparse_categorical_accuracy: 0.4568 - val_loss: 1.6525 - val_sparse_categorical_accuracy: 0.6145\n",
      "Epoch 12/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 1.6915 - sparse_categorical_accuracy: 0.5114 - val_loss: 1.5277 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 13/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 1.5634 - sparse_categorical_accuracy: 0.5250 - val_loss: 1.3735 - val_sparse_categorical_accuracy: 0.6867\n",
      "Epoch 14/600\n",
      "14/14 [==============================] - 1s 67ms/step - loss: 1.4874 - sparse_categorical_accuracy: 0.5773 - val_loss: 1.2980 - val_sparse_categorical_accuracy: 0.7108\n",
      "Epoch 15/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 1.4223 - sparse_categorical_accuracy: 0.6091 - val_loss: 1.1791 - val_sparse_categorical_accuracy: 0.8554\n",
      "Epoch 16/600\n",
      "14/14 [==============================] - 1s 65ms/step - loss: 1.2809 - sparse_categorical_accuracy: 0.6318 - val_loss: 1.0970 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 17/600\n",
      "14/14 [==============================] - 1s 76ms/step - loss: 1.1825 - sparse_categorical_accuracy: 0.6955 - val_loss: 1.0486 - val_sparse_categorical_accuracy: 0.7590\n",
      "Epoch 18/600\n",
      "14/14 [==============================] - 1s 60ms/step - loss: 1.1564 - sparse_categorical_accuracy: 0.6545 - val_loss: 0.9304 - val_sparse_categorical_accuracy: 0.8434\n",
      "Epoch 19/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 1.0487 - sparse_categorical_accuracy: 0.729 - 1s 50ms/step - loss: 1.0487 - sparse_categorical_accuracy: 0.7295 - val_loss: 0.9138 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 20/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.9457 - sparse_categorical_accuracy: 0.7591 - val_loss: 0.8406 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 21/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.9373 - sparse_categorical_accuracy: 0.7477 - val_loss: 0.8491 - val_sparse_categorical_accuracy: 0.7711\n",
      "Epoch 22/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.8945 - sparse_categorical_accuracy: 0.7545 - val_loss: 0.7272 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 23/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.8348 - sparse_categorical_accuracy: 0.7659 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 24/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.7271 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.6113 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 25/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.5575 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 26/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6591 - sparse_categorical_accuracy: 0.8273 - val_loss: 0.5505 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 27/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.6003 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.6052 - val_sparse_categorical_accuracy: 0.8313\n",
      "Epoch 28/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.5528 - sparse_categorical_accuracy: 0.8523 - val_loss: 0.5175 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 29/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.5417 - sparse_categorical_accuracy: 0.8636 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 30/600\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.4759 - sparse_categorical_accuracy: 0.868 - 1s 50ms/step - loss: 0.4759 - sparse_categorical_accuracy: 0.8682 - val_loss: 0.4242 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 31/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.4827 - sparse_categorical_accuracy: 0.8750 - val_loss: 0.3938 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 32/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.4883 - sparse_categorical_accuracy: 0.8636 - val_loss: 0.3634 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 33/600\n",
      "14/14 [==============================] - 1s 61ms/step - loss: 0.4627 - sparse_categorical_accuracy: 0.8727 - val_loss: 0.4196 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 34/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.4475 - sparse_categorical_accuracy: 0.8909 - val_loss: 0.3292 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 35/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.4221 - sparse_categorical_accuracy: 0.8955 - val_loss: 0.3494 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 36/600\n",
      "14/14 [==============================] - 1s 53ms/step - loss: 0.4023 - sparse_categorical_accuracy: 0.8977 - val_loss: 0.3679 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 37/600\n",
      "14/14 [==============================] - 1s 58ms/step - loss: 0.3778 - sparse_categorical_accuracy: 0.8932 - val_loss: 0.3279 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 38/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.3443 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.2607 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 39/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.3401 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.3762 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 40/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.3317 - sparse_categorical_accuracy: 0.9136 - val_loss: 0.2691 - val_sparse_categorical_accuracy: 0.9157\n",
      "Epoch 41/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2889 - sparse_categorical_accuracy: 0.9205 - val_loss: 0.2566 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 42/600\n",
      "14/14 [==============================] - 1s 45ms/step - loss: 0.2780 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2575 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 43/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2974 - sparse_categorical_accuracy: 0.9227 - val_loss: 0.2201 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 44/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.2759 - sparse_categorical_accuracy: 0.9318 - val_loss: 0.2791 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 45/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 52ms/step - loss: 0.2594 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.1987 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 46/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.2676 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.2563 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 47/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.2169 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2807 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 48/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.2517 - sparse_categorical_accuracy: 0.9295 - val_loss: 0.2312 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 49/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.2715 - sparse_categorical_accuracy: 0.9273 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 50/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.2183 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.3040 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 51/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.2276 - sparse_categorical_accuracy: 0.9409 - val_loss: 0.1877 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 52/600\n",
      "14/14 [==============================] - 1s 57ms/step - loss: 0.1938 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.2080 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 53/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1751 - sparse_categorical_accuracy: 0.9545 - val_loss: 0.1507 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 54/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1746 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.2071 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 55/600\n",
      "14/14 [==============================] - 1s 54ms/step - loss: 0.1634 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1791 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 56/600\n",
      "14/14 [==============================] - 1s 46ms/step - loss: 0.1458 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1761 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 57/600\n",
      "14/14 [==============================] - 1s 63ms/step - loss: 0.1486 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1690 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 58/600\n",
      "14/14 [==============================] - 1s 52ms/step - loss: 0.1474 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.2115 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 59/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1804 - sparse_categorical_accuracy: 0.9477 - val_loss: 0.2194 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 60/600\n",
      "14/14 [==============================] - 1s 51ms/step - loss: 0.1320 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1615 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 61/600\n",
      "14/14 [==============================] - 1s 56ms/step - loss: 0.1609 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1999 - val_sparse_categorical_accuracy: 0.9518\n",
      "Epoch 62/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1207 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1760 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 63/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1390 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.2835 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 64/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1582 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.2116 - val_sparse_categorical_accuracy: 0.9398\n",
      "Epoch 65/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1514 - sparse_categorical_accuracy: 0.9636 - val_loss: 0.1222 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 66/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1330 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2075 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 67/600\n",
      "14/14 [==============================] - 1s 43ms/step - loss: 0.1211 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1218 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 68/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.1115 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2242 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 69/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1368 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.1652 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 70/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1296 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 71/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1381 - sparse_categorical_accuracy: 0.9568 - val_loss: 0.2110 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 72/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.2830 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 73/600\n",
      "14/14 [==============================] - 1s 49ms/step - loss: 0.1620 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1454 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 74/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1521 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.2670 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 75/600\n",
      "14/14 [==============================] - 1s 50ms/step - loss: 0.1288 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1237 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 76/600\n",
      "14/14 [==============================] - 1s 55ms/step - loss: 0.1153 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.1532 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 77/600\n",
      "14/14 [==============================] - 1s 48ms/step - loss: 0.0882 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1309 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 78/600\n",
      "14/14 [==============================] - 1s 42ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1414 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 79/600\n",
      "14/14 [==============================] - 1s 44ms/step - loss: 0.1459 - sparse_categorical_accuracy: 0.9523 - val_loss: 0.1070 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 80/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.1124 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1734 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 81/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.1235 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 82/600\n",
      "14/14 [==============================] - 0s 34ms/step - loss: 0.0754 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1432 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 83/600\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0806 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1010 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 84/600\n",
      "14/14 [==============================] - 0s 35ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1630 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 85/600\n",
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0784 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1402 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 86/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0742 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1624 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 87/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0605 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.1955 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 88/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0846 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1586 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 89/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0734 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1053 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 90/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 36ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1088 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 91/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0810 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.1226 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 92/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0738 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.1637 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 93/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0721 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.1793 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 94/600\n",
      "14/14 [==============================] - 1s 40ms/step - loss: 0.0956 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1310 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 95/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0691 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1792 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 96/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.1711 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 97/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.0904 - sparse_categorical_accuracy: 0.9795 - val_loss: 0.2363 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 98/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0617 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1647 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 99/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0612 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.2379 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 100/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0767 - sparse_categorical_accuracy: 0.9705 - val_loss: 0.2193 - val_sparse_categorical_accuracy: 0.9639\n",
      "Epoch 101/600\n",
      "14/14 [==============================] - 1s 39ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9773 - val_loss: 0.1144 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 102/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0667 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.1286 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 103/600\n",
      "14/14 [==============================] - 1s 38ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1513 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 104/600\n",
      "14/14 [==============================] - 1s 37ms/step - loss: 0.0542 - sparse_categorical_accuracy: 0.9864 - val_loss: 0.1757 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 105/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0786 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1896 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 106/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.1032 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2318 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 107/600\n",
      "14/14 [==============================] - 1s 47ms/step - loss: 0.1086 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1547 - val_sparse_categorical_accuracy: 0.9759\n",
      "Epoch 108/600\n",
      "14/14 [==============================] - 1s 41ms/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9818 - val_loss: 0.1170 - val_sparse_categorical_accuracy: 0.9759\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp4uk4i7m8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\andre\\AppData\\Local\\Temp\\tmp4uk4i7m8\\assets\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model = None\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu', name='data')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax', name='result'))\n",
    "model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "testsplit = StratifiedShuffleSplit(n_splits = 1, test_size = 0.2)\n",
    "\n",
    "for train_index, test_index in testsplit.split(formatwavedata, labels):\n",
    "    X_train, X_test = formatwavedata[train_index], formatwavedata[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('hand_model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_val, y_val)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = model.predict(X_val)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = y_val\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
