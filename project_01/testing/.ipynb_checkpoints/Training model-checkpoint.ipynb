{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gestures = [\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8,\n",
    "    9\n",
    "]\n",
    "num_samples = 75\n",
    "num_gestures = len(gestures)\n",
    "\n",
    "one_hot = np.eye(len(gestures))\n",
    "\n",
    "fulldata = pd.DataFrame(columns = ['aX','aY','aZ','gX','gY','gZ'])\n",
    "formatdata = pd.DataFrame()\n",
    "labels = []\n",
    "\n",
    "for idx, gesture in enumerate(gestures):\n",
    "    for i in range(1, num_samples+1):\n",
    "        filepath = 'test_{0}_{1}.csv'.format(gesture, i)\n",
    "        data = pd.read_csv(filepath, index_col=False)\n",
    "        \n",
    "        data['aX'] = (data['aX'] + 4*9.81) / (2*4*9.81)\n",
    "        data['aY'] = (data['aY'] + 4*9.81) / (2*4*9.81)\n",
    "        data['aZ'] = (data['aZ'] + 4*9.81) / (2*4*9.81)\n",
    "        data['gX'] = (data['gX'] + 7.5) / (2*7.5)\n",
    "        data['gY'] = (data['gY'] + 7.5) / (2*7.5)\n",
    "        data['gZ'] = (data['gZ'] + 7.5) / (2*7.5)\n",
    "        \n",
    "        fulldata = fulldata.append(data)\n",
    "        dataf = data.to_numpy().flatten().tolist()\n",
    "        formatdata[idx*num_samples+i-1] = dataf\n",
    "        label = one_hot[idx]\n",
    "        labels.append(label)\n",
    "\n",
    "formatdata = formatdata.transpose().to_numpy()\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "127500/10/250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(formatdata, labels, test_size=0.15)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    "\n",
    ")\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "prediction = np.round(model.predict(X_test), decimals=3)\n",
    "prediction\n",
    "\n",
    "prediction_lbl = np.argmax(prediction, axis=1)\n",
    "test_lbl = np.where(y_test == 1)[1]\n",
    "\n",
    "cm = confusion_matrix(test_lbl, prediction_lbl, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out different network sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5098 - categorical_accuracy: 0.8496\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5865 - categorical_accuracy: 0.8938\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4795 - categorical_accuracy: 0.8761\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3611 - categorical_accuracy: 0.8761\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3632 - categorical_accuracy: 0.9292\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3710 - categorical_accuracy: 0.8761\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7674 - categorical_accuracy: 0.8053\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8020 - categorical_accuracy: 0.8496\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4288 - categorical_accuracy: 0.8850\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5973 - categorical_accuracy: 0.8407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.52664173, 0.86814159])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "hyperparameters = pd.DataFrame()\n",
    "\n",
    "validation = []\n",
    "for i in range(1,11):\n",
    "\n",
    "    model = None\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(2048, activation='relu')) # relu is used for performance\n",
    "    model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "    early_stopping = callbacks.EarlyStopping(\n",
    "        min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "        patience=25, # how many epochs to wait before stopping\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(formatdata, labels, test_size=0.15)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)\n",
    "\n",
    "    history = model.fit(X_train, y_train, \n",
    "                        epochs=600,\n",
    "                        batch_size=64,\n",
    "                        callbacks=[early_stopping],\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        verbose=0)\n",
    "    \n",
    "    validation.append(model.evaluate(X_test, y_test))\n",
    "\n",
    "np.average(validation, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6501 - categorical_accuracy: 0.8052\n",
      "2\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3955 - categorical_accuracy: 0.8571\n",
      "3\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2367 - categorical_accuracy: 0.9091\n",
      "4\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6304 - categorical_accuracy: 0.8052\n",
      "5\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.9463 - categorical_accuracy: 0.7143\n",
      "6\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.0883 - categorical_accuracy: 0.7532\n",
      "7\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6646 - categorical_accuracy: 0.7662\n",
      "8\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4035 - categorical_accuracy: 0.9091\n",
      "9\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7413 - categorical_accuracy: 0.7662\n",
      "10\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4451 - categorical_accuracy: 0.8961\n",
      "11\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3767 - categorical_accuracy: 0.8701\n",
      "12\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7869 - categorical_accuracy: 0.7792\n",
      "13\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7112 - categorical_accuracy: 0.8182\n",
      "14\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5593 - categorical_accuracy: 0.8182\n",
      "15\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4044 - categorical_accuracy: 0.8701\n",
      "16\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8363 - categorical_accuracy: 0.8182\n",
      "17\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9393 - categorical_accuracy: 0.7143\n",
      "18\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4366 - categorical_accuracy: 0.8701\n",
      "19\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5094 - categorical_accuracy: 0.8442\n",
      "20\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.6281 - categorical_accuracy: 0.8182\n",
      "21\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4048 - categorical_accuracy: 0.8831\n",
      "22\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3407 - categorical_accuracy: 0.8701\n",
      "23\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4591 - categorical_accuracy: 0.8961\n",
      "24\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6008 - categorical_accuracy: 0.8312\n",
      "25\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3603 - categorical_accuracy: 0.8701\n",
      "26\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3398 - categorical_accuracy: 0.8701\n",
      "27\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.7896 - categorical_accuracy: 0.8182\n",
      "28\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4882 - categorical_accuracy: 0.8961\n",
      "29\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5389 - categorical_accuracy: 0.8442\n",
      "30\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5858 - categorical_accuracy: 0.8182\n",
      "31\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.9030 - categorical_accuracy: 0.7013\n",
      "32\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7356 - categorical_accuracy: 0.8571\n",
      "33\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7920 - categorical_accuracy: 0.7922\n",
      "34\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.4168 - categorical_accuracy: 0.8312\n",
      "35\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7336 - categorical_accuracy: 0.8442\n",
      "36\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3888 - categorical_accuracy: 0.9091\n",
      "37\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.4792 - categorical_accuracy: 0.8701\n",
      "38\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6597 - categorical_accuracy: 0.8312\n",
      "39\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6218 - categorical_accuracy: 0.7662\n",
      "40\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4429 - categorical_accuracy: 0.8442\n",
      "41\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5203 - categorical_accuracy: 0.8182\n",
      "42\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8062 - categorical_accuracy: 0.7273\n",
      "43\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8222 - categorical_accuracy: 0.7403\n",
      "44\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5631 - categorical_accuracy: 0.8571\n",
      "45\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.3106 - categorical_accuracy: 0.8961\n",
      "46\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4036 - categorical_accuracy: 0.8961\n",
      "47\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.6162 - categorical_accuracy: 0.7662\n",
      "48\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7157 - categorical_accuracy: 0.7792\n",
      "49\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8918 - categorical_accuracy: 0.8312\n",
      "50\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7523 - categorical_accuracy: 0.8961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "hyperparameters = pd.DataFrame()\n",
    "for n in range(4,9):\n",
    "    validation = []\n",
    "    for i in range(1,11):\n",
    "        \n",
    "        model = None\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Dense(2048, activation='relu')) # relu is used for performance\n",
    "        model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "        early_stopping = callbacks.EarlyStopping(\n",
    "            min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "            patience=25, # how many epochs to wait before stopping\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(formatdata, labels, test_size=0.15)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85)\n",
    "\n",
    "        history = model.fit(X_train, y_train, \n",
    "                            epochs=600,\n",
    "                            batch_size=2**n,\n",
    "                            callbacks=[early_stopping],\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            verbose=0)\n",
    "        print((n-4)*10+i)\n",
    "        validation.append(model.evaluate(X_test, y_test))\n",
    "        \n",
    "    hyperparameters[2**n] = np.average(validation, axis=0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.620182</td>\n",
       "      <td>0.618816</td>\n",
       "      <td>0.490793</td>\n",
       "      <td>0.617349</td>\n",
       "      <td>0.640195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.822078</td>\n",
       "      <td>0.859740</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.820779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        16        32        64        128       256\n",
       "0  0.620182  0.618816  0.490793  0.617349  0.640195\n",
       "1  0.818182  0.822078  0.859740  0.824675  0.820779"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(2048, activation='relu')) # relu is used for performance\n",
    "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(len(gestures), activation='softmax'))\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=25, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(formatdata, labels, test_size=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=600,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stopping],\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
